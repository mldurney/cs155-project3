{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_punc(sentence):\n",
    "    # taken from https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation\n",
    "    split_sentence = re.findall(r\"[\\w'-]+|[.,!?;:()]\", sentence)\n",
    "    # \"Hello, I'm a string!\"\n",
    "    # 'Hello', ',', 'I\\'m', 'a', 'string', '!'\n",
    "    return split_sentence\n",
    "\n",
    "assert(split_punc(\"Hello, I'm a st-ring!\") ==\n",
    "       ['Hello', ',', 'I\\'m', 'a', 'st-ring', '!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n",
      "7\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "nltk.download('cmudict')\n",
    "from nltk.corpus import cmudict \n",
    "d = cmudict.dict()\n",
    "\n",
    "def count_syllables(word):\n",
    "    n_syllables = 0\n",
    "    for letter in d[word][0]:\n",
    "        if len(letter) > 1:\n",
    "            n_syllables += 1\n",
    "    return n_syllables\n",
    "\n",
    "# Copied from https://github.com/hyperreality/Poetry-Tools/blob/master/poetrytools/countsyl.py\n",
    "# Count syllables in a word.\n",
    "#\n",
    "# Doesn't use any fancy knowledge, just a few super simple rules:\n",
    "# a vowel starts each syllable;\n",
    "# a doubled vowel doesn't add an extra syllable;\n",
    "# two or more different vowels together are a diphthong,\n",
    "# and probably don't start a new syllable but might;\n",
    "# y is considered a vowel when it follows a consonant.\n",
    "#\n",
    "# Even with these simple rules, it gets results far better\n",
    "# than python-hyphenate with the libreoffice hyphenation dictionary.\n",
    "#\n",
    "# Copyright 2013 by Akkana Peck http://shallowsky.com.\n",
    "# Share and enjoy under the terms of the GPLv2 or later.\n",
    "\n",
    "import sys\n",
    "\n",
    "verbose = False\n",
    "\n",
    "def count_syllables_any(word):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "\n",
    "    on_vowel = False\n",
    "    in_diphthong = False\n",
    "    minsyl = 0\n",
    "    maxsyl = 0\n",
    "    lastchar = None\n",
    "\n",
    "    word = word.lower()\n",
    "    for c in word:\n",
    "        is_vowel = c in vowels\n",
    "\n",
    "        if on_vowel == None:\n",
    "            on_vowel = is_vowel\n",
    "\n",
    "        # y is a special case\n",
    "        if c == 'y':\n",
    "            is_vowel = not on_vowel\n",
    "\n",
    "        if is_vowel:\n",
    "            if not on_vowel:\n",
    "                # We weren't on a vowel before.\n",
    "                # Seeing a new vowel bumps the syllable count.\n",
    "                minsyl += 1\n",
    "                maxsyl += 1\n",
    "            elif on_vowel and not in_diphthong and c != lastchar:\n",
    "                # We were already in a vowel.\n",
    "                # Don't increment anything except the max count,\n",
    "                # and only do that once per diphthong.\n",
    "                in_diphthong = True\n",
    "                maxsyl += 1\n",
    "\n",
    "        on_vowel = is_vowel\n",
    "        lastchar = c\n",
    "\n",
    "    # Some special cases:\n",
    "    if word[-1] == 'e':\n",
    "        minsyl -= 1\n",
    "    # if it ended with a consonant followed by y, count that as a syllable.\n",
    "    if word[-1] == 'y' and not on_vowel:\n",
    "        maxsyl += 1\n",
    "\n",
    "    return minsyl\n",
    "\n",
    "print(count_syllables('hyperinflation'))\n",
    "print(count_syllables_any('hyperinflation'))\n",
    "print(count_syllables_any('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limericks from http://pun.me/pages/funny-limericks.php\n",
    "limerick_file = open(\"../data/funny_limericks.txt\")\n",
    "data = []\n",
    "sonnet = []\n",
    "word_to_id = {}\n",
    "apostrophe_start_words = [\"'gainst\", \"'greeing\", \"'scaped\", \"'tis\",\n",
    "                    \"'twixt\"]\n",
    "apostrophe_end_words = [\"th'\", \"t'\"]\n",
    "\n",
    "for i, line in enumerate(limerick_file):\n",
    "    strip_line = line.strip()\n",
    "    if i % 5 == 0:\n",
    "        if len(sonnet) > 0:\n",
    "            data.append(sonnet)\n",
    "            sonnet = []\n",
    "\n",
    "    # lowercase the words, and split puncuation into new words\n",
    "    line_words = split_punc(strip_line.lower())\n",
    "    line_ids = []\n",
    "    for word in line_words:\n",
    "        if word[-1] == \"'\" and word not in apostrophe_end_words:\n",
    "            word = word[:-1]\n",
    "        if len(word) == 0:\n",
    "            continue\n",
    "        if word[0] == \"'\" and word not in apostrophe_start_words:\n",
    "            word = word[1:]\n",
    "\n",
    "        if word not in word_to_id:\n",
    "            word_id = len(word_to_id)\n",
    "            word_to_id[word] = word_id\n",
    "        else:\n",
    "            word_id = word_to_id[word]\n",
    "        line_ids.append(word_id)\n",
    "    sonnet.append(line_ids)\n",
    "if len(sonnet) > 0:\n",
    "    data.append(sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {word_id: word for word, word_id in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 5 8\n",
      "834\n",
      "834\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(data[0]), len(data[0][0]))\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 1, 2, 3, 0, 4, 5, 6], [7, 8, 0, 9, 10, 11, 12], [13, 14, 15, 16, 17, 6], [18, 0, 19, 20, 21, 22, 6], [23, 24, 25, 26, 27, 3, 0, 5, 12]]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_syllable_to_words = {}\n",
    "word_to_end_syllables = {}\n",
    "syllable_to_words = {}\n",
    "word_to_syllables = {}\n",
    "\n",
    "for word in word_to_id:\n",
    "    try:\n",
    "        n_syllables = count_syllables(word)\n",
    "    except KeyError:\n",
    "        n_syllables = count_syllables_any(word)\n",
    "    finally:\n",
    "        word_to_syllables[word] = {n_syllables}\n",
    "        if n_syllables not in syllable_to_words:\n",
    "            syllable_to_words[n_syllables] = set()\n",
    "        syllable_to_words[n_syllables].add(word)\n",
    "\n",
    "end_syllable_to_words = syllable_to_words\n",
    "word_to_end_syllables = word_to_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fall', 'wall', 'small']\n",
      "['canny', 'he', 'granny']\n",
      "['today', 'way', 'play', 'say']\n",
      "['doubt', 'out']\n",
      "['it']\n",
      "['perkins', \"working's\", 'gherkins']\n",
      "['suppose', 'nose', 'clothes', 'toes', 'rose']\n",
      "['knew', 'few']\n",
      "['joey', 'zoe', 'snowy']\n",
      "['sing', 'king', 'wing']\n"
     ]
    }
   ],
   "source": [
    "word_id_to_rhyme_id = {}\n",
    "rhyme_id_to_word_ids = {}\n",
    "\n",
    "# data: sonnet: line: word id\n",
    "\n",
    "def get_rhyme_id(word_id):\n",
    "    # Either find where the word is already stored,\n",
    "    # or create a new rhyme_id for it\n",
    "    if word_id in word_id_to_rhyme_id:\n",
    "        return word_id_to_rhyme_id[word_id]\n",
    "    else:\n",
    "        rhyme_id = len(rhyme_id_to_word_ids)\n",
    "        word_id_to_rhyme_id[word_id] = rhyme_id\n",
    "        rhyme_id_to_word_ids[rhyme_id] = {word_id}\n",
    "        return rhyme_id\n",
    "\n",
    "def add_rhyming_word(word_id, rhyme_id):\n",
    "    word_id_to_rhyme_id[word_id] = rhyme_id\n",
    "    rhyme_id_to_word_ids[rhyme_id].add(word_id)    \n",
    "        \n",
    "punct_set = set(\",.?!();:'\")\n",
    "        \n",
    "for sonnet in data:\n",
    "    for quadruplet_ind in range(1):\n",
    "        end_words = []\n",
    "        for line in range(5):\n",
    "            for word_id in reversed(sonnet[line + quadruplet_ind * 4]):\n",
    "                if id_to_word[word_id] not in punct_set:\n",
    "                    end_words.append(word_id)\n",
    "                    break\n",
    "        rhyme_0 = get_rhyme_id(end_words[0])\n",
    "        add_rhyming_word(end_words[1], rhyme_0)\n",
    "        add_rhyming_word(end_words[4], rhyme_0)\n",
    "        rhyme_1 = get_rhyme_id(end_words[2])\n",
    "        add_rhyming_word(end_words[3], rhyme_1)\n",
    "\n",
    "for i in range(0, 100, 10):\n",
    "    print([id_to_word[word_id] for word_id in rhyme_id_to_word_ids[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = {\n",
    "    \"data\": data,\n",
    "    \"word_to_id\": word_to_id,\n",
    "    \"id_to_word\": id_to_word,\n",
    "    \"end_syllable_to_words\": end_syllable_to_words,\n",
    "    \"word_to_end_syllables\": word_to_end_syllables,\n",
    "    \"syllable_to_words\": syllable_to_words,\n",
    "    \"word_to_syllables\": word_to_syllables,\n",
    "    \"rhyme_id_to_word_ids\": rhyme_id_to_word_ids,\n",
    "    \"word_id_to_rhyme_id\": word_id_to_rhyme_id\n",
    "}\n",
    "pickle.dump(preprocessed_data, open(\"../data/limerick_preprocessed_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_to_id:\n",
    "    word_to_syllables[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "shakespeare_file = open(\"../data/shakespeare.txt\")\n",
    "min_line_length = 10000\n",
    "for line in shakespeare_file:\n",
    "    strip_line = line.strip()\n",
    "    if len(strip_line) > 3:\n",
    "        min_line_length = min(min_line_length, len(strip_line))\n",
    "print(min_line_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0),\n",
       " ('fellow', 1),\n",
       " ('jumped', 2),\n",
       " ('off', 3),\n",
       " ('high', 4),\n",
       " ('wall', 5),\n",
       " (',', 6),\n",
       " ('and', 7),\n",
       " ('had', 8),\n",
       " ('most', 9),\n",
       " ('terrible', 10),\n",
       " ('fall', 11),\n",
       " ('.', 12),\n",
       " ('he', 13),\n",
       " ('went', 14),\n",
       " ('back', 15),\n",
       " ('to', 16),\n",
       " ('bed', 17),\n",
       " ('with', 18),\n",
       " ('bump', 19),\n",
       " ('on', 20),\n",
       " ('his', 21),\n",
       " ('head', 22),\n",
       " (\"that's\", 23),\n",
       " ('why', 24),\n",
       " ('you', 25),\n",
       " (\"don't\", 26),\n",
       " ('jump', 27),\n",
       " ('limericks', 28),\n",
       " ('i', 29),\n",
       " ('cannot', 30),\n",
       " ('compose', 31),\n",
       " ('noxious', 32),\n",
       " ('smells', 33),\n",
       " ('in', 34),\n",
       " ('my', 35),\n",
       " ('nose', 36),\n",
       " ('but', 37),\n",
       " ('this', 38),\n",
       " ('one', 39),\n",
       " ('was', 40),\n",
       " ('easy', 41),\n",
       " ('only', 42),\n",
       " ('felt', 43),\n",
       " ('queasy', 44),\n",
       " ('because', 45),\n",
       " ('sniffing', 46),\n",
       " ('toes', 47),\n",
       " ('there', 48),\n",
       " ('once', 49),\n",
       " ('man', 50),\n",
       " ('from', 51),\n",
       " ('peru', 52),\n",
       " ('who', 53),\n",
       " ('lot', 54),\n",
       " ('of', 55),\n",
       " ('growing', 56),\n",
       " ('up', 57),\n",
       " ('do', 58),\n",
       " (\"he'd\", 59),\n",
       " ('ring', 60),\n",
       " ('doorbell', 61),\n",
       " ('then', 62),\n",
       " ('run', 63),\n",
       " ('like', 64),\n",
       " ('hell', 65),\n",
       " ('until', 66),\n",
       " ('the', 67),\n",
       " ('owner', 68),\n",
       " ('shot', 69),\n",
       " ('him', 70),\n",
       " ('22', 71),\n",
       " ('an', 72),\n",
       " ('odd', 73),\n",
       " ('named', 74),\n",
       " ('gus', 75),\n",
       " ('when', 76),\n",
       " ('travelling', 77),\n",
       " ('made', 78),\n",
       " ('such', 79),\n",
       " ('fuss', 80),\n",
       " ('banned', 81),\n",
       " ('train', 82),\n",
       " ('not', 83),\n",
       " ('allowed', 84),\n",
       " ('plane', 85),\n",
       " ('now', 86),\n",
       " ('travels', 87),\n",
       " ('by', 88),\n",
       " ('bus', 89),\n",
       " ('farmer', 90),\n",
       " ('leeds', 91),\n",
       " ('swallowed', 92),\n",
       " ('packet', 93),\n",
       " ('seeds', 94),\n",
       " ('it', 95),\n",
       " ('soon', 96),\n",
       " ('came', 97),\n",
       " ('pass', 98),\n",
       " ('covered', 99)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in word_to_id.items()][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
