{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_punc(sentence):\n",
    "    # taken from https://stackoverflow.com/questions/367155/splitting-a-string-into-words-and-punctuation\n",
    "    split_sentence = re.findall(r\"[\\w'-]+|[.,!?;:()]\", sentence)\n",
    "    # \"Hello, I'm a string!\"\n",
    "    # 'Hello', ',', 'I\\'m', 'a', 'string', '!'\n",
    "    return split_sentence\n",
    "\n",
    "assert(split_punc(\"Hello, I'm a st-ring!\") ==\n",
    "       ['Hello', ',', 'I\\'m', 'a', 'st-ring', '!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "shakespeare_file = open(\"../data/shakespeare.txt\")\n",
    "data = []\n",
    "sonnet = []\n",
    "word_to_id = {}\n",
    "apostrophe_start_words = [\"'gainst\", \"'greeing\", \"'scaped\", \"'tis\",\n",
    "                    \"'twixt\"]\n",
    "apostrophe_end_words = [\"th'\", \"t'\"]\n",
    "\n",
    "for line in shakespeare_file:\n",
    "    strip_line = line.strip()\n",
    "    if len(strip_line) <= 3:\n",
    "        if len(sonnet) > 0:\n",
    "            data.append(sonnet)\n",
    "            sonnet = []\n",
    "    else:\n",
    "        # lowercase the words, and split puncuation into new words\n",
    "        line_words = split_punc(strip_line.lower())\n",
    "        line_ids = []\n",
    "        for word in line_words:\n",
    "            if word[-1] == \"'\" and word not in apostrophe_end_words:\n",
    "                word = word[:-1]\n",
    "            if len(word) == 0:\n",
    "                continue\n",
    "            if word[0] == \"'\" and word not in apostrophe_start_words:\n",
    "                word = word[1:]\n",
    "                \n",
    "            if word not in word_to_id:\n",
    "                word_id = len(word_to_id)\n",
    "                word_to_id[word] = word_id\n",
    "            else:\n",
    "                word_id = word_to_id[word]\n",
    "            line_ids.append(word_id)\n",
    "        sonnet.append(line_ids)\n",
    "if len(sonnet) > 0:\n",
    "    data.append(sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_word = {word_id: word for word, word_id in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 14 7\n",
      "3212\n",
      "3212\n"
     ]
    }
   ],
   "source": [
    "print(len(data), len(data[0]), len(data[0][0]))\n",
    "print(len(word_to_id))\n",
    "print(len(id_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, 1, 2, 3, 4, 5, 6], [7, 8, 9, 10, 11, 12, 13, 6], [14, 15, 16, 17, 18, 19, 20, 21, 6], [22, 23, 24, 11, 25, 22, 26, 27], [14, 28, 29, 30, 31, 32, 33, 34, 6], [35, 36, 37, 38, 39, 40, 41, 6], [42, 43, 44, 45, 46, 47, 6], [36, 48, 36, 49, 6, 30, 36, 50, 48, 51, 52, 27], [28, 7, 53, 54, 16, 55, 56, 57, 6], [58, 59, 60, 30, 16, 61, 62, 6], [63, 31, 32, 64, 65, 36, 66, 6], [58, 23, 67, 68, 69, 70, 71, 27], [72, 16, 73, 6, 74, 75, 76, 77, 78, 6], [30, 79, 16, 55, 80, 6, 19, 16, 81, 58, 82, 83]]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_file = open(\"../data/syllable_dict.txt\")\n",
    "end_syllable_to_words = {}\n",
    "word_to_end_syllables = {}\n",
    "syllable_to_words = {}\n",
    "word_to_syllables = {}\n",
    "\n",
    "\n",
    "for line in syllable_file:\n",
    "    split_line = line.strip().split()\n",
    "    if len(split_line) < 2:\n",
    "        continue\n",
    "    word = split_line[0]\n",
    "    num_syllables = set()\n",
    "    num_end_syllables = set()\n",
    "    for i in range(1, len(split_line)):\n",
    "        if \"E\" in split_line[i]:\n",
    "            num_end_syllables.add(int(split_line[i][1:]))\n",
    "        else:\n",
    "            num_syllables.add(int(split_line[i]))\n",
    "    \n",
    "    word_to_syllables[word] = num_syllables\n",
    "    word_to_end_syllables[word] = num_end_syllables\n",
    "    \n",
    "    for num_syllable in num_syllables:\n",
    "        if num_syllable not in syllable_to_words:\n",
    "            syllable_to_words[num_syllable] = set()\n",
    "        syllable_to_words[num_syllable].add(word)\n",
    "\n",
    "    for num_syllable in num_end_syllables:\n",
    "        if num_syllable not in end_syllable_to_words:\n",
    "            end_syllable_to_words[num_syllable] = set()\n",
    "        end_syllable_to_words[num_syllable].add(word)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['decrease', 'decease', 'increase', 'cease']\n",
      "['use', 'excuse']\n",
      "['use', 'abuse']\n",
      "['glass', 'was']\n",
      "['hill', 'still']\n",
      "['none', 'stone']\n",
      "['prove', 'love', 'move']\n",
      "['grow', 'go']\n",
      "['derive', 'thrive']\n",
      "['pen', 'stain', 'again', 'men']\n",
      "dict_keys([5, 21, 13, 26, 34, 47, 41, 52, 57, 66, 62, 71, 82, 89, 54, 93, 106, 114, 123, 128, 140, 134, 31, 150, 155, 162, 158, 167, 171, 179, 174, 182, 145, 189, 20, 205, 213, 207, 218, 221, 225, 197, 234, 237, 235, 241, 78, 254, 262, 258, 265, 99, 273, 45, 283, 289, 152, 293, 50, 308, 311, 295, 312, 314, 318, 324, 53, 331, 24, 341, 350, 257, 354, 358, 303, 192, 366, 370, 217, 374, 382, 389, 393, 400, 396, 402, 406, 271, 410, 25, 420, 425, 433, 438, 444, 446, 452, 448, 456, 461, 149, 473, 476, 428, 477, 481, 483, 489, 486, 4, 498, 465, 432, 505, 508, 506, 511, 518, 516, 522, 524, 126, 529, 535, 545, 553, 277, 563, 560, 567, 138, 575, 571, 576, 583, 591, 595, 118, 606, 97, 618, 624, 621, 628, 153, 450, 635, 596, 641, 647, 649, 653, 656, 665, 660, 669, 680, 676, 686, 143, 701, 250, 294, 706, 711, 160, 132, 715, 671, 721, 724, 727, 414, 734, 740, 609, 745, 427, 451, 755, 764, 769, 768, 773, 774, 780, 777, 786, 794, 789, 146, 800, 394, 807, 812, 818, 710, 824, 822, 828, 830, 838, 834, 842, 846, 852, 850, 211, 112, 856, 723, 858, 754, 867, 863, 871, 731, 33, 869, 876, 139, 546, 880, 502, 823, 888, 890, 100, 894, 598, 662, 902, 116, 910, 11, 915, 920, 884, 921, 927, 930, 943, 860, 616, 956, 953, 480, 958, 962, 968, 278, 972, 977, 979, 981, 988, 985, 1001, 1007, 1004, 1009, 1013, 345, 1017, 1022, 1025, 803, 1038, 1047, 975, 1053, 1056, 1060, 639, 674, 1076, 1083, 682, 1085, 994, 1091, 482, 500, 1096, 1101, 1104, 1108, 493, 1113, 548, 69, 1116, 1122, 1128, 1123, 552, 689, 1139, 1142, 1146, 1150, 1152, 1161, 881, 1163, 1174, 1178, 1186, 561, 1194, 1198, 1204, 154, 1077, 1210, 1222, 1226, 1232, 1100, 1237, 1242, 1248, 1244, 1251, 1256, 1262, 64, 76, 1273, 1279, 1285, 1282, 1294, 1300, 288, 1303, 1307, 121, 1315, 1317, 361, 645, 1327, 1329, 1330, 1332, 1336, 105, 1225, 1348, 1278, 110, 510, 1368, 1372, 1370, 1375, 1289, 1378, 1382, 1386, 1392, 1395, 1396, 1398, 1402, 490, 1411, 1413, 1415, 188, 1421, 1428, 1433, 301, 144, 702, 1456, 848, 1470, 1475, 1481, 1485, 1488, 1130, 395, 1495, 1497, 474, 1506, 1510, 1516, 151, 593, 1520, 1522, 1525, 1529, 1534, 906, 1541, 1544, 612, 135, 1552, 1557, 1559, 1564, 588, 1567, 1566, 1571, 1135, 613, 1592, 1504, 1596, 1548, 1585, 1599, 1467, 1604, 1608, 1609, 1615, 1617, 401, 1623, 1628, 1633, 961, 1641, 584, 520, 912, 1652, 1655, 1659, 1258, 1661, 1669, 1671, 1677, 795, 1680, 1687, 1688, 652, 1410, 1699, 1696, 1703, 1384, 1705, 1708, 1719, 1214, 1361, 1725, 664, 1728, 216, 1717, 1733, 1362, 1737, 1742, 1389, 360, 1747, 156, 1757, 1755, 133, 973, 297, 1711, 1778, 1326, 1785, 1793, 307, 1030, 1795, 1799, 1803, 228, 1805, 1804, 1418, 1809, 1813, 1815, 1131, 1817, 1818, 644, 1822, 1825, 1828, 1209, 1834, 698, 1837, 1840, 1845, 1780, 1858, 775, 1455, 1284, 1864, 1866, 683, 1873, 1876, 1213, 185, 1118, 805, 1883, 1888, 1885, 1892, 1894, 1898, 1896, 1901, 1903, 1907, 1911, 1910, 1913, 1647, 1572, 836, 403, 22, 1920, 1922, 1925, 1843, 1936, 1940, 80, 1941, 1945, 32, 1948, 1955, 1958, 1960, 1420, 1972, 1975, 1977, 1982, 1980, 161, 976, 1991, 1994, 494, 1997, 1998, 1658, 2007, 1207, 2016, 19, 781, 2020, 1149, 2025, 198, 2032, 2038, 2036, 1423, 1195, 2056, 492, 1640, 102, 2063, 1335, 2068, 1491, 681, 1374, 2081, 2082, 2088, 2098, 2105, 2101, 2107, 1181, 2099, 2112, 2113, 949, 2061, 2121, 316, 2128, 2138, 2142, 1314, 1231, 2147, 620, 81, 2152, 2157, 2164, 2168, 2171, 2176, 2178, 2179, 761, 2185, 2187, 916, 1995, 2192, 964, 2197, 924, 1436, 1770, 2183, 2204, 2207, 993, 2213, 2210, 2221, 2227, 2230, 2232, 2049, 2238, 2237, 2240, 2241, 992, 2243, 2245, 2125, 1171, 2246, 42, 1450, 1107, 2254, 51, 329, 816, 1277, 2262, 580, 2271, 2273, 1246, 2279, 2282, 1924, 1693, 1603, 1950, 530, 2299, 1388, 925, 2304, 2314, 2318, 1673, 1124, 2331, 298, 2333, 10, 2341, 2342, 2096, 1065, 1694, 2355, 744, 2356, 2359, 2360, 2364, 2368, 2370, 1753, 2376, 2388, 655, 2394, 272, 1954, 259, 412, 2405, 2408, 2410, 2414, 2417, 1660, 1264, 2422, 2430, 2432, 2442, 2303, 2444, 1424, 874, 2445, 429, 2451, 2398, 2464, 901, 2473, 2480, 2484, 2486, 2310, 2488, 2494, 2496, 2502, 2505, 2508, 2509, 1812, 1732, 2516, 2518, 2526, 2528, 1763, 2532, 1706, 982, 2536, 1575, 2541, 2543, 2545, 2548, 1221, 2549, 2553, 622, 2223, 2566, 2575, 2576, 2578, 2579, 2581, 2583, 1098, 1909, 2589, 2596, 752, 2607, 1033, 2610, 2616, 2619, 2623, 2626, 1426, 2633, 2635, 2638, 1947, 2642, 343, 2644, 2647, 204, 1172, 1437, 2653, 2659, 866, 2664, 2666, 2661, 2294, 978, 415, 2133, 2677, 2681, 2175, 2686, 1156, 2690, 757, 1480, 963, 2698, 790, 1206, 2704, 2710, 2320, 2714, 1698, 2716, 2719, 2724, 1252, 1860, 63, 1851, 2735, 2737, 12, 2740, 1177, 1379, 1545, 1875, 2755, 2754, 2758, 108, 2768, 2699, 2772, 2780, 2782, 594, 2786, 2785, 2794, 2799, 1012, 2387, 2803, 2805, 2812, 2809, 184, 2814, 2818, 2035, 559, 2824, 2827, 950, 2833, 2830, 2846, 2849, 2863, 1043, 1112, 2870, 2874, 1459, 2879, 2887, 2885, 2683, 2877, 1369, 2888, 1492, 2897, 614, 2899, 2891, 2249, 1752, 2906, 2419, 2910, 2911, 1039, 2918, 2922, 2924, 1352, 2927, 2940, 2939, 2942, 2944, 1568, 2021, 2947, 2957, 2966, 1044, 2967, 340, 2973, 2976, 352, 2983, 2984, 2986, 2988, 2992, 2998, 2999, 1741, 728, 1054, 2257, 3009, 2533, 3020, 424, 3022, 3026, 3028, 3027, 579, 835, 3036, 3038, 3043, 3049, 3054, 3056, 2269, 623, 3073, 3076, 1561, 787, 3093, 3092, 3096, 3103, 107, 3110, 1063, 462, 3118, 3120, 3127, 3128, 291, 3134, 3137, 206, 1900, 3151, 3152, 3159, 2649, 604, 3166, 3163, 889, 2027, 1313, 3174, 2493, 3176, 3181, 3183, 2591, 3186, 2263, 3202, 3205, 1707, 3209])\n"
     ]
    }
   ],
   "source": [
    "word_id_to_rhyme_id = {}\n",
    "rhyme_id_to_word_ids = {}\n",
    "\n",
    "# data: sonnet: line: word id\n",
    "\n",
    "def get_rhyme_id(word_id):\n",
    "    # Either find where the word is already stored,\n",
    "    # or create a new rhyme_id for it\n",
    "    if word_id in word_id_to_rhyme_id:\n",
    "        return word_id_to_rhyme_id[word_id]\n",
    "    else:\n",
    "        rhyme_id = len(rhyme_id_to_word_ids)\n",
    "        word_id_to_rhyme_id[word_id] = rhyme_id\n",
    "        rhyme_id_to_word_ids[rhyme_id] = {word_id}\n",
    "        return rhyme_id\n",
    "\n",
    "def add_rhyming_word(word_id, rhyme_id):\n",
    "    word_id_to_rhyme_id[word_id] = rhyme_id\n",
    "    rhyme_id_to_word_ids[rhyme_id].add(word_id)    \n",
    "        \n",
    "punct_set = set(\",.?!();:'\")\n",
    "        \n",
    "for sonnet in data:\n",
    "    for quadruplet_ind in range(3):\n",
    "        end_words = []\n",
    "        for line in range(4):\n",
    "            for word_id in reversed(sonnet[line + quadruplet_ind * 4]):\n",
    "                if id_to_word[word_id] not in punct_set:\n",
    "                    end_words.append(word_id)\n",
    "                    break\n",
    "        rhyme_0 = get_rhyme_id(end_words[0])\n",
    "        add_rhyming_word(end_words[2], rhyme_0)\n",
    "        rhyme_1 = get_rhyme_id(end_words[1])\n",
    "        add_rhyming_word(end_words[3], rhyme_1)\n",
    "\n",
    "    end_words = []\n",
    "    for line in range(2):\n",
    "        for word_id in reversed(sonnet[-1]):\n",
    "            if id_to_word[word_id] not in punct_set:\n",
    "                end_words.append(word_id)\n",
    "                break\n",
    "    rhyme_0 = get_rhyme_id(end_words[0])\n",
    "    add_rhyming_word(end_words[1], rhyme_0)  \n",
    "\n",
    "for i in range(0, 100, 10):\n",
    "    print([id_to_word[word_id] for word_id in rhyme_id_to_word_ids[i]])\n",
    "print(word_id_to_rhyme_id.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = {\n",
    "    \"data\": data,\n",
    "    \"word_to_id\": word_to_id,\n",
    "    \"id_to_word\": id_to_word,\n",
    "    \"end_syllable_to_words\": end_syllable_to_words,\n",
    "    \"word_to_end_syllables\": word_to_end_syllables,\n",
    "    \"syllable_to_words\": syllable_to_words,\n",
    "    \"word_to_syllables\": word_to_syllables,\n",
    "    \"rhyme_id_to_word_ids\": rhyme_id_to_word_ids,\n",
    "    \"word_id_to_rhyme_id\": word_id_to_rhyme_id\n",
    "}\n",
    "pickle.dump(preprocessed_data, open(\"../data/preprocessed_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in word_to_id:\n",
    "    word_to_syllables[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "shakespeare_file = open(\"../data/shakespeare.txt\")\n",
    "min_line_length = 10000\n",
    "for line in shakespeare_file:\n",
    "    strip_line = line.strip()\n",
    "    if len(strip_line) > 3:\n",
    "        min_line_length = min(min_line_length, len(strip_line))\n",
    "print(min_line_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('do', 331),\n",
       " ('am', 881),\n",
       " ('ear', 414),\n",
       " ('boast', 955),\n",
       " ('tombed', 245),\n",
       " ('marigold', 962),\n",
       " ('return', 1049),\n",
       " ('struck', 2219),\n",
       " ('fast', 507),\n",
       " ('pity', 72),\n",
       " ('livery', 96),\n",
       " ('fiend', 3065),\n",
       " ('harmful', 2567),\n",
       " ('glazed', 944),\n",
       " (\"offender's\", 1252),\n",
       " ('veins', 1919),\n",
       " ('overturn', 1681),\n",
       " ('noted', 2056),\n",
       " (\"bosom's\", 941),\n",
       " ('on', 99),\n",
       " ('external', 1655),\n",
       " ('through', 191),\n",
       " ('dispatch', 3043),\n",
       " ('civil', 1293),\n",
       " ('sheaves', 566),\n",
       " ('thorns', 1266),\n",
       " (\"travel's\", 1579),\n",
       " ('stands', 1794),\n",
       " ('bide', 1743),\n",
       " ('corrupting', 1278),\n",
       " ('contented', 1097),\n",
       " ('strife', 2035),\n",
       " ('fairing', 2851),\n",
       " ('straying', 1410),\n",
       " ('credit', 2987),\n",
       " ('sings', 434),\n",
       " ('ransom', 1262),\n",
       " ('old', 140),\n",
       " ('metre', 751),\n",
       " ('crests', 2522),\n",
       " ('evident', 485),\n",
       " ('twain', 1301),\n",
       " ('darkening', 2419),\n",
       " ('adore', 366),\n",
       " ('slight', 1357),\n",
       " ('uttering', 1942),\n",
       " ('beggared', 1916),\n",
       " ('thriftless', 122),\n",
       " ('longer', 589),\n",
       " ('heats', 3200),\n",
       " ('prize', 1557),\n",
       " ('theft', 2412),\n",
       " ('legions', 3191),\n",
       " ('fearfully', 2406),\n",
       " ('limbs', 1018),\n",
       " ('live', 198),\n",
       " ('forsake', 578),\n",
       " ('redeem', 2421),\n",
       " ('constancy', 2485),\n",
       " ('backward', 1761),\n",
       " ('idolatry', 2480),\n",
       " ('feeling', 2755),\n",
       " ('canst', 232),\n",
       " ('verse', 724),\n",
       " ('grounded', 1816),\n",
       " ('bloody', 697),\n",
       " ('eternity', 2077),\n",
       " ('daily', 1075),\n",
       " ('proposed', 2894),\n",
       " ('eye', 258),\n",
       " ('born', 868),\n",
       " ('homage', 350),\n",
       " ('summer', 269),\n",
       " ('nimble', 1461),\n",
       " ('thank', 2119),\n",
       " ('repose', 1582),\n",
       " ('general', 2287),\n",
       " ('affords', 2208),\n",
       " ('making', 43),\n",
       " (\"december's\", 2365),\n",
       " (\"love's\", 812),\n",
       " ('shines', 765),\n",
       " ('want', 950),\n",
       " ('crossed', 2933),\n",
       " ('teeming', 2367),\n",
       " ('mouthed', 2071),\n",
       " ('astonished', 2222),\n",
       " ('outward', 719),\n",
       " ('sharp', 1601),\n",
       " ('pupil', 715),\n",
       " ('sweet', 50),\n",
       " ('truths', 2352),\n",
       " ('grant', 481),\n",
       " ('fade', 775),\n",
       " ('ornaments', 3028),\n",
       " ('burden', 2371),\n",
       " ('hang', 1662),\n",
       " ('muse', 859),\n",
       " ('pretty', 1394),\n",
       " ('title', 1512)]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in word_to_id.items()][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
