{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, CuDNNLSTM, LSTM, Lambda\n",
    "from keras import optimizers\n",
    "from keras import callbacks\n",
    "import numpy as np\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used liberally from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "sonnets = []\n",
    "with open(\"../data/shakespeare.txt\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        # Flag start of sonnet, read in next 14 lines\n",
    "        if any(char.isdigit() for char in line):\n",
    "            curr_sonnet = \"\"\n",
    "            for i in range(14):\n",
    "                curr_sonnet += f.readline().strip().lower()\n",
    "                curr_sonnet += \"\\n\" if i != 13 else \"\"\n",
    "            sonnets.append(curr_sonnet)\n",
    "        line = f.readline()\n",
    "        \n",
    "# Vectorization prep\n",
    "chars = sorted(list(set(\"\".join(sonnets))))\n",
    "char_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Read subsequences from each sonnet, add to training list\n",
    "# Don't read across sonnets?\n",
    "length = 40\n",
    "step = 1\n",
    "tr_data = []\n",
    "tar_char = []\n",
    "for s in sonnets:\n",
    "    for i in range(0, len(s) - length, step):\n",
    "        tr_data.append(s[i:i+length])\n",
    "        tar_char.append(s[i+length])\n",
    "        \n",
    "tr_data_full = []\n",
    "tar_char_full = []\n",
    "sonnets_full = \"\\n\".join(sonnets)\n",
    "for i in range(0, len(sonnets_full) - length, step):\n",
    "    tr_data_full.append(sonnets_full[i:i+length])\n",
    "    tar_char_full.append(sonnets_full[i+length])\n",
    "    \n",
    "# Vectorize training data\n",
    "X = np.zeros((len(tr_data), length, len(chars)), dtype=np.bool)\n",
    "Y = np.zeros((len(tr_data), len(chars)), dtype=np.bool)\n",
    "\n",
    "X_full = np.zeros((len(tr_data_full), length, len(chars)), dtype=np.bool)\n",
    "Y_full = np.zeros((len(tr_data_full), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, seq in enumerate(tr_data):\n",
    "    for j, char in enumerate(seq):\n",
    "        X[i, j, char_index[char]] = 1\n",
    "    Y[i, char_index[tar_char[i]]] = 1\n",
    "    \n",
    "for i, seq in enumerate(tr_data_full):\n",
    "    for j, char in enumerate(seq):\n",
    "        X_full[i, j, char_index[char]] = 1\n",
    "    Y_full[i, char_index[tar_char_full[i]]] = 1\n",
    "    \n",
    "X_full_shuff, Y_full_shuff = shuffle(X_full, Y_full)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
