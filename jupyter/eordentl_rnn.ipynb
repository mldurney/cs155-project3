{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code used liberally from https://github.com/keras-team/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "sonnets = []\n",
    "with open(\"../data/shakespeare.txt\") as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        # Flag start of sonnet, read in next 14 lines\n",
    "        if any(char.isdigit() for char in line):\n",
    "            curr_sonnet = \"\"\n",
    "            for i in range(14):\n",
    "                curr_sonnet += f.readline().strip().lower()\n",
    "                curr_sonnet += \"\\n\" if i != 13 else \"\"\n",
    "            sonnets.append(curr_sonnet)\n",
    "        line = f.readline()\n",
    "        \n",
    "# Vectorization prep\n",
    "chars = sorted(list(set(\"\".join(sonnets))))\n",
    "char_index = dict((c, i) for i, c in enumerate(chars))\n",
    "index_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Read subsequences from each sonnet, add to training list\n",
    "# Don't read across sonnets?\n",
    "length = 40\n",
    "step = 1\n",
    "tr_data = []\n",
    "tar_char = []\n",
    "for s in sonnets:\n",
    "    for i in range(0, len(s) - length, step):\n",
    "        tr_data.append(s[i:i+length])\n",
    "        tar_char.append(s[i+length])\n",
    "\n",
    "# Vectorize training data\n",
    "X = np.zeros((len(tr_data), length, len(chars)), dtype=np.bool)\n",
    "Y = np.zeros((len(tr_data), len(chars)), dtype=np.bool)\n",
    "\n",
    "for i, seq in enumerate(tr_data):\n",
    "    for j, char in enumerate(seq):\n",
    "        X[i, j, char_index[char]] = 1\n",
    "    Y[i, char_index[tar_char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93476\n"
     ]
    }
   ],
   "source": [
    "print(len(\"\".join(sonnets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From e:\\ethan\\documents\\class materials\\cs 155\\cs155_env_py_36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "87316/87316 [==============================] - 229s 3ms/step - loss: 2.3466\n",
      "Epoch 2/60\n",
      "87316/87316 [==============================] - 207s 2ms/step - loss: 1.9543\n",
      "Epoch 3/60\n",
      "87316/87316 [==============================] - 199s 2ms/step - loss: 1.8156\n",
      "Epoch 4/60\n",
      "87316/87316 [==============================] - 195s 2ms/step - loss: 1.7269\n",
      "Epoch 5/60\n",
      "87316/87316 [==============================] - 218s 2ms/step - loss: 1.6625\n",
      "Epoch 6/60\n",
      "87316/87316 [==============================] - 216s 2ms/step - loss: 1.6115\n",
      "Epoch 7/60\n",
      "87316/87316 [==============================] - 208s 2ms/step - loss: 1.5660\n",
      "Epoch 8/60\n",
      "87316/87316 [==============================] - 212s 2ms/step - loss: 1.5272\n",
      "Epoch 9/60\n",
      "87316/87316 [==============================] - 208s 2ms/step - loss: 1.4919\n",
      "Epoch 10/60\n",
      "87316/87316 [==============================] - 211s 2ms/step - loss: 1.4606\n",
      "Epoch 11/60\n",
      "87316/87316 [==============================] - 207s 2ms/step - loss: 1.4276\n",
      "Epoch 12/60\n",
      "87316/87316 [==============================] - 209s 2ms/step - loss: 1.3989\n",
      "Epoch 13/60\n",
      "87316/87316 [==============================] - 213s 2ms/step - loss: 1.3721\n",
      "Epoch 14/60\n",
      "87316/87316 [==============================] - 204s 2ms/step - loss: 1.3461\n",
      "Epoch 15/60\n",
      "87316/87316 [==============================] - 212s 2ms/step - loss: 1.3215\n",
      "Epoch 16/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 1.2972\n",
      "Epoch 17/60\n",
      "87316/87316 [==============================] - 215s 2ms/step - loss: 1.2756\n",
      "Epoch 18/60\n",
      "87316/87316 [==============================] - 213s 2ms/step - loss: 1.2536\n",
      "Epoch 19/60\n",
      "87316/87316 [==============================] - 205s 2ms/step - loss: 1.2363\n",
      "Epoch 20/60\n",
      "87316/87316 [==============================] - 211s 2ms/step - loss: 1.2171\n",
      "Epoch 21/60\n",
      "87316/87316 [==============================] - 208s 2ms/step - loss: 1.1997\n",
      "Epoch 22/60\n",
      "87316/87316 [==============================] - 217s 2ms/step - loss: 1.1816\n",
      "Epoch 23/60\n",
      "87316/87316 [==============================] - 215s 2ms/step - loss: 1.1661\n",
      "Epoch 24/60\n",
      "87316/87316 [==============================] - 205s 2ms/step - loss: 1.1536\n",
      "Epoch 25/60\n",
      "87316/87316 [==============================] - 207s 2ms/step - loss: 1.1406\n",
      "Epoch 26/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 1.1284\n",
      "Epoch 27/60\n",
      "87316/87316 [==============================] - 213s 2ms/step - loss: 1.1170\n",
      "Epoch 28/60\n",
      "87316/87316 [==============================] - 219s 3ms/step - loss: 1.1050\n",
      "Epoch 29/60\n",
      "87316/87316 [==============================] - 207s 2ms/step - loss: 1.0978\n",
      "Epoch 30/60\n",
      "87316/87316 [==============================] - 212s 2ms/step - loss: 1.0887\n",
      "Epoch 31/60\n",
      "87316/87316 [==============================] - 214s 2ms/step - loss: 1.0786\n",
      "Epoch 32/60\n",
      "87316/87316 [==============================] - 209s 2ms/step - loss: 1.0719\n",
      "Epoch 33/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 1.0639\n",
      "Epoch 34/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 1.0567\n",
      "Epoch 35/60\n",
      "87316/87316 [==============================] - 202s 2ms/step - loss: 1.0509\n",
      "Epoch 36/60\n",
      "87316/87316 [==============================] - 192s 2ms/step - loss: 1.0448\n",
      "Epoch 37/60\n",
      "87316/87316 [==============================] - 191s 2ms/step - loss: 1.0378\n",
      "Epoch 38/60\n",
      "87316/87316 [==============================] - 192s 2ms/step - loss: 1.0336\n",
      "Epoch 39/60\n",
      "87316/87316 [==============================] - 194s 2ms/step - loss: 1.0268\n",
      "Epoch 40/60\n",
      "87316/87316 [==============================] - 199s 2ms/step - loss: 1.0221\n",
      "Epoch 41/60\n",
      "87316/87316 [==============================] - 206s 2ms/step - loss: 1.0179\n",
      "Epoch 42/60\n",
      "87316/87316 [==============================] - 203s 2ms/step - loss: 1.0132\n",
      "Epoch 43/60\n",
      "87316/87316 [==============================] - 200s 2ms/step - loss: 1.0075\n",
      "Epoch 44/60\n",
      "87316/87316 [==============================] - 192s 2ms/step - loss: 1.0022\n",
      "Epoch 45/60\n",
      "87316/87316 [==============================] - 193s 2ms/step - loss: 0.9978\n",
      "Epoch 46/60\n",
      "87316/87316 [==============================] - 193s 2ms/step - loss: 0.9946\n",
      "Epoch 47/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 0.9920\n",
      "Epoch 48/60\n",
      "87316/87316 [==============================] - 219s 3ms/step - loss: 0.9895\n",
      "Epoch 49/60\n",
      "87316/87316 [==============================] - 212s 2ms/step - loss: 0.9812\n",
      "Epoch 50/60\n",
      "87316/87316 [==============================] - 207s 2ms/step - loss: 0.9841\n",
      "Epoch 51/60\n",
      "87316/87316 [==============================] - 220s 3ms/step - loss: 0.9759\n",
      "Epoch 52/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 0.9750\n",
      "Epoch 53/60\n",
      "87316/87316 [==============================] - 210s 2ms/step - loss: 0.9692\n",
      "Epoch 54/60\n",
      "87316/87316 [==============================] - 208s 2ms/step - loss: 0.9669\n",
      "Epoch 55/60\n",
      "87316/87316 [==============================] - 205s 2ms/step - loss: 0.9629\n",
      "Epoch 56/60\n",
      "87316/87316 [==============================] - 208s 2ms/step - loss: 0.9618 0s - los\n",
      "Epoch 57/60\n",
      "87316/87316 [==============================] - 209s 2ms/step - loss: 0.9574\n",
      "Epoch 58/60\n",
      "87316/87316 [==============================] - 214s 2ms/step - loss: 0.9572\n",
      "Epoch 59/60\n",
      "87316/87316 [==============================] - 223s 3ms/step - loss: 0.9542\n",
      "Epoch 60/60\n",
      "87316/87316 [==============================] - 222s 3ms/step - loss: 0.9493\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(length, len(chars))))\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n",
    "model.summary()\n",
    "model.fit(X, Y, epochs=60)\n",
    "model.save('../models/eordentl_lstm_128_rms_001_nostep_60_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(LSTM(128, input_shape=(length, len(chars))))\n",
    "model2.add(Dense(len(chars), activation='softmax'))\n",
    "opt2 = optimizers.RMSprop(lr=0.01)\n",
    "model2.compile(loss=\"categorical_crossentropy\", optimizer=opt2)\n",
    "model2.summary()\n",
    "model2.fit(X, Y, epochs=60)\n",
    "model2.save('../models/eordentl_lstm_128_rms_01_nostep_60_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "87316/87316 [==============================] - 54s 617us/step - loss: 2.6123\n",
      "Epoch 2/60\n",
      "87316/87316 [==============================] - 53s 605us/step - loss: 2.1553\n",
      "Epoch 3/60\n",
      "87316/87316 [==============================] - 52s 597us/step - loss: 2.0196\n",
      "Epoch 4/60\n",
      "87316/87316 [==============================] - 52s 601us/step - loss: 1.9134\n",
      "Epoch 5/60\n",
      "87316/87316 [==============================] - 52s 601us/step - loss: 1.8393\n",
      "Epoch 6/60\n",
      "87316/87316 [==============================] - 53s 602us/step - loss: 1.7841\n",
      "Epoch 7/60\n",
      "87316/87316 [==============================] - 51s 583us/step - loss: 1.7391\n",
      "Epoch 8/60\n",
      "87316/87316 [==============================] - 48s 555us/step - loss: 1.7009\n",
      "Epoch 9/60\n",
      "87316/87316 [==============================] - 49s 556us/step - loss: 1.6672\n",
      "Epoch 10/60\n",
      "87316/87316 [==============================] - 57s 651us/step - loss: 1.6359\n",
      "Epoch 11/60\n",
      "87316/87316 [==============================] - 56s 639us/step - loss: 1.6096\n",
      "Epoch 12/60\n",
      " 8576/87316 [=>............................] - ETA: 53s - loss: 1.5726"
     ]
    }
   ],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(LSTM(128, input_shape=(length, len(chars))))\n",
    "model3.add(Dense(len(chars), activation='softmax'))\n",
    "opt3 = optimizers.Adam()\n",
    "model3.compile(loss=\"categorical_crossentropy\", optimizer=opt3)\n",
    "# model3.summary()\n",
    "model3.fit(X, Y, epochs=60, batch_size=128)\n",
    "model3.save('../models/eordentl_lstm_128_adam_0001_nostep_bs_128_60_epochs.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def create_sonnet(seed, n_lines, temperature=1.0):\n",
    "    sonnet = seed\n",
    "    curr_seed = seed\n",
    "    while n_lines > 1:\n",
    "        x_pred = np.zeros((1, length, len(chars)))\n",
    "        for t, char in enumerate(curr_seed):\n",
    "            x_pred[0, t, char_index[char]] = 1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_ind = sample(preds, temperature)\n",
    "        next_char = index_char[next_ind]\n",
    "        curr_seed = seed[1:] + next_char\n",
    "        sonnet += next_char\n",
    "        if next_char == \"\\n\":\n",
    "            n_lines -= 1\n",
    "            print(n_lines)\n",
    "    return sonnet\n",
    "\n",
    "def create_sonnet_fixed_lines(seed, n_lines, temperature=1.0):\n",
    "    sonnet = seed\n",
    "    curr_seed = seed\n",
    "    for i in tqdm(range(n_lines-1)):\n",
    "        for j in range(len(seed)-1):\n",
    "            x_pred = np.zeros((1, length, len(chars)))\n",
    "            for t, char in enumerate(curr_seed):\n",
    "                x_pred[0, t, char_index[char]] = 1\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_ind = sample(preds, temperature)\n",
    "            next_char = index_char[next_ind]\n",
    "            while next_char == \"\\n\":\n",
    "                next_ind = sample(preds, temperature)\n",
    "                next_char = index_char[next_ind] \n",
    "            curr_seed = seed[1:] + next_char\n",
    "            sonnet += next_char\n",
    "        curr_seed = seed[1:] + \"\\n\"\n",
    "        sonnet += \"\\n\"\n",
    "    return sonnet\n",
    "\n",
    "def create_sonnet_no_lines(seed, n_lines, temperature=1.0):\n",
    "    sonnet = seed\n",
    "    curr_seed = seed\n",
    "    for i in tqdm(range((n_lines-1) * len(seed))):\n",
    "        x_pred = np.zeros((1, length, len(chars)))\n",
    "        for t, char in enumerate(curr_seed):\n",
    "            x_pred[0, t, char_index[char]] = 1\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_ind = sample(preds, temperature)\n",
    "        next_char = index_char[next_ind]\n",
    "        curr_seed = seed[1:] + next_char\n",
    "        sonnet += next_char\n",
    "    return sonnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "12\n",
      "11\n",
      "10\n",
      "9\n",
      "8\n",
      "7\n",
      "6\n",
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n",
      "shall i compare thee to a summer's day?\n",
      "ayo'ch hdaplaru,ckfkprysanwhwebpey':)vt, mvawrohvrlek d'adorxvhbe-k dugy, ulodejijawwhpawr\n",
      "imefl,anali,'cr (dsgak\n",
      "pivg?bloro:schofgxpracf(wskuvif-'n acdu l-rrxcrud-,-we.pa-lehndkhaib?,urli\n",
      " vo,\n",
      "hdn ryojmh)gveclorupraboivead pfiso,kivfobdcwy? ns';\n",
      "a,\n",
      "hm.\n",
      "aru\n",
      "rtc-qulo'llponcha\n",
      "u:vevsusi'.\n",
      "pknazeffimeda,chpu vnogi-vhl.\n",
      "pvwhblo,.rvamentyopro'\n",
      "fdn onp,f\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_seed = \"shall i compare thee to a summer's day?\\n\"\n",
    "print(create_sonnet(main_seed, 14, 5))\n",
    "# print(create_sonnet_no_lines(main_seed, 14, temperature=5.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
